{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatic music generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Tensorflow 2.0\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf \n",
        "\n",
        "# Download and import the MIT 6.S191 package\n",
        "!pip install mitdeeplearning\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "# Import all remaining packages\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
        "\n",
        "# Check that we are using a GPU, if not switch runtimes\n",
        "#   using Runtime > Change Runtime Type > GPU\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRoPJYblhqkW",
        "outputId": "143b6fae-ab25-441e-843f-ef996daf5d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mitdeeplearning\n",
            "  Downloading mitdeeplearning-0.2.0.tar.gz (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (4.62.3)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from mitdeeplearning) (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->mitdeeplearning) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->mitdeeplearning) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->mitdeeplearning) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->mitdeeplearning) (0.16.0)\n",
            "Building wheels for collected packages: mitdeeplearning\n",
            "  Building wheel for mitdeeplearning (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mitdeeplearning: filename=mitdeeplearning-0.2.0-py3-none-any.whl size=2115442 sha256=4282e85b9b2f880fd1a69f626a2a6a0e6e693b3b185335ac861d84b8d0b6f2e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/b9/4f/99b7c8c5c75355550b83e1fcfc02956fb40c35eb01e2262877\n",
            "Successfully built mitdeeplearning\n",
            "Installing collected packages: mitdeeplearning\n",
            "Successfully installed mitdeeplearning-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypq1rgLcXNAu",
        "outputId": "71e013f9-af46-4e45-eaf7-b1bdd8827321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "my_conn=create_engine(\"sqlite://///content/drive/MyDrive/Dataset/snippets-dev.db\")"
      ],
      "metadata": {
        "id": "0ua2mZV1Yj9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering for extract only python snippets"
      ],
      "metadata": {
        "id": "Su2YKeuAbOm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "con = sqlite3.connect('/content/drive/MyDrive/Dataset/snippets-dev.db')"
      ],
      "metadata": {
        "id": "wPtOTQg-l8HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filtered_data = pd.read_sql_query(\"SELECT * FROM snippets WHERE language='Python' \",con)\n",
        "filtered_data.to_csv(r'/content/drive/MyDrive/Dataset/pythonSmall.csv', index = False)"
      ],
      "metadata": {
        "id": "Z-f0OcL6ZDhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging the source programs:"
      ],
      "metadata": {
        "id": "Zpaz9zeBbfRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql_query(\"SELECT snippet, repo_file_name FROM snippets WHERE language='Python' GROUP BY repo_file_name \",con)\n",
        "print (df)\n"
      ],
      "metadata": {
        "id": "oNpFLGxAZ904",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b005b91-fa89-4eae-f242-53bf4a081702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 snippet                               repo_file_name\n",
            "0              circle.set_stroke(BLUE_E, width=4)\\n  ...                 3b1b/manim/example_scenes.py\n",
            "1              output_label_p2 = Tex(\"f(b)\")\\n       ...                      3b1b/manim/logo/logo.py\n",
            "2      from manimlib.utils.bezier import *\\nfrom mani...              3b1b/manim/manimlib/__init__.py\n",
            "3          # Methods for interpolation, the mean of a...   3b1b/manim/manimlib/animation/animation.py\n",
            "4          def get_stroke_color(self, vmobject):\\n   ...    3b1b/manim/manimlib/animation/creation.py\n",
            "...                                                  ...                                          ...\n",
            "52199  #   default values for settings configurable i...             zulip/zulip/zproject/settings.py\n",
            "52200  \\nfrom zerver.lib.db import TimeTrackingConnec...  zulip/zulip/zproject/test_extra_settings.py\n",
            "52201  ]\\n\\n# user_uploads -> zerver.views.upload.ser...                 zulip/zulip/zproject/urls.py\n",
            "52202  THUMBOR_LOCAL_FILE_TYPE = \"local_file\"\\n\\n\\nde...      zulip/zulip/zthumbor/loaders/helpers.py\n",
            "52203  TC_AWS_STORE_METADATA = False  # Store result ...     zulip/zulip/zthumbor/thumbor_settings.py\n",
            "\n",
            "[52204 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertion of BAM:"
      ],
      "metadata": {
        "id": "mFt7tMnBbjF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "splitCode = []\n",
        "\n",
        "for i in range(10) :\n",
        "  x =df.loc[i, \"snippet\"]\n",
        "  chunks = x.split('\\n')\n",
        "\n",
        "  s= str(i)\n",
        "  fileName = \"myfile\"+s+\".txt\";\n",
        "\n",
        "  splitCode = [] \n",
        "  for lst in chunks:  \n",
        "    converted_line = \"\"\n",
        "    for i in lst:\n",
        "      if i == ' ':\n",
        "        converted_line += ' '\t\n",
        "      else:\n",
        "        converted_line += u'\\u25a0'\t\n",
        "    splitCode.append(converted_line)\n",
        "  \n",
        "  f = open(fileName, \"w\")\n",
        "  for element in splitCode:\n",
        "      f.write(element + \"\\n\")\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "B-AuB7KhaQdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from PIL import ImageFont\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "\n",
        "font = ImageFont.truetype('/content/arial.ttf', 15)\n",
        "\n",
        "for i in range(10) :\n",
        "      s= str(i)\n",
        "      fileName = \"/content/myfile\"+s+\".txt\";\n",
        "\n",
        "      filepath = open(fileName, \"r\")\n",
        "      lines = filepath.readlines()\n",
        "      filepath.close()\n",
        "\n",
        "\n",
        "\n",
        "      width= len(max(lines, key=len)) * 18 + 50\n",
        "      height = len(lines) * 18 + 50\n",
        "      img = Image.new('RGB', (width, height), color = (255,255,255))\n",
        "      img_draw = ImageDraw.Draw(img)\n",
        "      j=0\n",
        "\n",
        "      for i in lines:\n",
        "        img_draw.text((0,j),i,fill='black', font=font)\n",
        "        j+=16\n",
        "      imageName = \"/content/sample_data/content\"+s+\".png\";\n",
        "      img.save(imageName)"
      ],
      "metadata": {
        "id": "AlyV4Nr8aY8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating FD:"
      ],
      "metadata": {
        "id": "9CN5VSmhb4Uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import scipy\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def rgb2gray(rgb):\n",
        "\n",
        "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
        "\n",
        "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
        "\n",
        "    return gray\n",
        "\n",
        "\n",
        "\n",
        "def fractal_dimension(Z, threshold=0.9):\n",
        "\n",
        "    # Only for 2d image\n",
        "\n",
        "    assert(len(Z.shape) == 2)\n",
        "\n",
        "\n",
        "\n",
        "    # From https://github.com/rougier/numpy-100 (#87)\n",
        "\n",
        "    def boxcount(Z, k):\n",
        "\n",
        "        S = np.add.reduceat(\n",
        "\n",
        "            np.add.reduceat(Z, np.arange(0, Z.shape[0], k), axis=0),\n",
        "\n",
        "                               np.arange(0, Z.shape[1], k), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "        # We count non-empty (0) and non-full boxes (k*k)\n",
        "\n",
        "        return len(np.where((S > 0) & (S < k*k))[0])\n",
        "\n",
        "\n",
        "\n",
        "    # Transform Z into a binary array\n",
        "\n",
        "    Z = (Z < threshold)\n",
        "\n",
        "\n",
        "\n",
        "    # Minimal dimension of image\n",
        "\n",
        "    p = min(Z.shape)\n",
        "\n",
        "\n",
        "\n",
        "    # Greatest power of 2 less than or equal to p\n",
        "\n",
        "    n = 2**np.floor(np.log(p)/np.log(2))\n",
        "\n",
        "\n",
        "\n",
        "    # Extract the exponent\n",
        "\n",
        "    n = int(np.log(n)/np.log(2))\n",
        "\n",
        "\n",
        "\n",
        "    # Build successive box sizes (from 2**n down to 2**1)\n",
        "\n",
        "    sizes = 2**np.arange(n, 1, -1)\n",
        "\n",
        "\n",
        "\n",
        "    # Actual box counting with decreasing size\n",
        "\n",
        "    counts = []\n",
        "\n",
        "    for size in sizes:\n",
        "\n",
        "        counts.append(boxcount(Z, size))\n",
        "\n",
        "\n",
        "\n",
        "    # Fit the successive log(sizes) with log (counts)\n",
        "\n",
        "    coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)\n",
        "\n",
        "    return -coeffs[0]\n",
        "\n",
        "\n",
        "for i in range(10) :\n",
        "      s= str(i)\n",
        "      imageName = \"/content/sample_data/content\"+s+\".png\";\n",
        "      I = rgb2gray(mpimg.imread(imageName))\n",
        "      print(\"FD: \", fractal_dimension(I))"
      ],
      "metadata": {
        "id": "02LNIdoGadq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dadc7cdb-973b-4cc5-f235-a645ac5deb62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FD:  1.486017717938463\n",
            "FD:  1.692707993003542\n",
            "FD:  1.6854831635503211\n",
            "FD:  1.5993498640793822\n",
            "FD:  1.6174012686640085\n",
            "FD:  1.5644849233800364\n",
            "FD:  1.4447103626531086\n",
            "FD:  1.5738532482890069\n",
            "FD:  1.5069017075889537\n",
            "FD:  1.4530465659197969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing to generate notes:"
      ],
      "metadata": {
        "id": "gwRhLvJxePx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data_2 = filtered_data.groupby(\"repo_file_name\")\n",
        "filtered_data_2"
      ],
      "metadata": {
        "id": "S9ivWdg-ZMK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e006d10c-ef48-4cc2-e7c2-e78192844765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f5c79027710>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def punctuationRemove(test_str):\n",
        "  punc = '''!()[]{};:'\"\\,<>./?@#$%^&*_~+'''\n",
        "\n",
        "  for ele in test_str:\n",
        "      if ele in punc:\n",
        "          test_str = test_str.replace(ele, \"c\")\n",
        "      if  ele == ' ':\n",
        "          test_str = test_str.replace(ele, '-') \n",
        "      if  ele == '=':\n",
        "          test_str = test_str.replace(ele, 'f') \n",
        "          \n",
        "  return test_str"
      ],
      "metadata": {
        "id": "1NadCJIEZo2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(code, message):\n",
        "    encoded = [c for c in message]\n",
        "    for i, c in enumerate(message):\n",
        "        try:\n",
        "            encoded[i] = code[c]\n",
        "        except KeyError:\n",
        "            pass\n",
        "    return ''.join(encoded)"
      ],
      "metadata": {
        "id": "mhMn4RZIdqww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code2Note = {\n",
        "   'b': 'B',\n",
        "   '0': 'A',\n",
        "   '1':'a',\n",
        "   '2':'B',\n",
        "   '3':'C',\n",
        "   '4':'c',\n",
        "   '5':'D',\n",
        "   '6':'d',\n",
        "   '7':'E',\n",
        "   '8':'F',\n",
        "   '9':'f',\n",
        "   '\\n':'G',\n",
        "   ':':'g',\n",
        "   'H': 'A',\n",
        "   'h':'a',\n",
        "   'I':'B',\n",
        "   'i':'C',\n",
        "   'J':'c',\n",
        "   'j':'D',\n",
        "   'K':'d',\n",
        "   'k':'E',\n",
        "   'L':'F',\n",
        "   'l':'f',\n",
        "   'M':'G',\n",
        "   'm':'g',\n",
        "   'N': 'A',\n",
        "   'n':'a',\n",
        "   'O':'B',\n",
        "   'o':'C',\n",
        "   'P':'c',\n",
        "   'p':'D',\n",
        "   'Q':'d',\n",
        "   'q':'E',\n",
        "   'R':'F',\n",
        "   'r':'f',\n",
        "   'S':'G',\n",
        "   's':'g',\n",
        "   'T': 'A',\n",
        "   't':'a',\n",
        "   'u':'B',\n",
        "   'U':'C',\n",
        "   'V':'c',\n",
        "   'v':'D',\n",
        "   'W':'d',\n",
        "   'w':'E',\n",
        "   'x':'F',\n",
        "   'X':'f',\n",
        "   'Y':'G',\n",
        "   'y':'g',\n",
        "   'Z':'c',\n",
        "   'z':'C',\n",
        "   'e':'E'\n",
        "}"
      ],
      "metadata": {
        "id": "lD9dMZBWduE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addRestNotes(s):\n",
        "  string_revised=\" \".join(s)\n",
        "  return string_revised"
      ],
      "metadata": {
        "id": "cubQMnszdy91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "fNo=-1\n",
        "\n",
        "for fname, codes in filtered_data_2:  # First tuple from iterator\n",
        "  chunks=[]\n",
        "  fNo+=1\n",
        "  for i in range(len(codes)):\n",
        "    c = str(codes[\"snippet\"])\n",
        "    chunks = c.split('\\n')\n",
        "\n",
        "    s= str(fNo)\n",
        "  \n",
        "  snippet=[]\n",
        "\n",
        "  for i in range(len(chunks)):\n",
        "      if(chunks[i]=='Name: snippet, dtype: object'):\n",
        "        continue \n",
        "\n",
        "      chunks[i]=re.sub(' +', ' ', chunks[i]) \n",
        "      chunks[i]=punctuationRemove(chunks[i]) \n",
        "      chunks[i]=encode(code2Note, chunks[i])\n",
        "      chunks[i]=addRestNotes(chunks[i])\n",
        "      chunks[i]=punctuationRemove(chunks[i])\n",
        "      snippet.append(punctuationRemove(chunks[i]))\n",
        "   \n",
        "  f = open(fileName, \"w\")\n",
        "  for element in snippet:\n",
        "      f.write(element + \"--\")\n",
        "  f.close()\n",
        " \n",
        "  "
      ],
      "metadata": {
        "id": "nb6_GOZXd329"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note to piano music"
      ],
      "metadata": {
        "id": "vlzimIqoeWsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "samplerate = 44100\n",
        "\n",
        "def get_wave(freq, duration=0.5):\n",
        "    \n",
        "    amplitude = 4096\n",
        "    t = np.linspace(0, duration, int(samplerate * duration))\n",
        "    wave = amplitude * np.sin(2 * np.pi * freq * t)\n",
        "    \n",
        "    return wave\n",
        "\n",
        "a_wave = get_wave(440, 1)"
      ],
      "metadata": {
        "id": "tMlw_9fbedSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "def get_piano_notes():\n",
        "   \n",
        "    # White keys are in Uppercase and black keys (sharps) are in lowercase\n",
        "    octave = ['C', 'c', 'D', 'd', 'E', 'F', 'f', 'G', 'g', 'A', 'a', 'B'] \n",
        "    base_freq = 261.63 \n",
        "    \n",
        "    note_freqs = {octave[i]: base_freq * pow(2,(i/12)) for i in range(len(octave))}        \n",
        "    note_freqs[''] = 0.0 \n",
        "    \n",
        "    return note_freqs\n",
        "  \n",
        "    note_freqs = get_piano_notes()\n",
        "    print(note_freqs)"
      ],
      "metadata": {
        "id": "54NKB215eorq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "def get_song_data(music_notes):\n",
        "    \n",
        "    note_freqs = get_piano_notes()\n",
        "    song = [get_wave(note_freqs[note]) for note in music_notes.split('-')]\n",
        "    song = np.concatenate(song)\n",
        "    return song"
      ],
      "metadata": {
        "id": "4hZgE4W7e62P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def codeNotes(music_notes,s):\n",
        "  print(music_notes)\n",
        "  data = get_song_data(music_notes)\n",
        "  data = data * (16300/np.max(data))\n",
        "  write(musicName, samplerate, data.astype(np.int16))"
      ],
      "metadata": {
        "id": "sxdc5bo0fBir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "for i in range(100) :\n",
        "      s= str(i)\n",
        "      #print(s)\n",
        "      if fileName.is_file():\n",
        "        f = open(fileName, \"r\")\n",
        "        noteLines=\"\"\n",
        "        noteLines=f.read()\n",
        "        f.close()\n",
        "       # print(noteLines)\n",
        "        codeNotes(noteLines,s)\n",
        "        noteLines=\"\""
      ],
      "metadata": {
        "id": "9IR0DX4rfEz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing the dataset"
      ],
      "metadata": {
        "id": "3aSLHCkPfk5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_midi(file):\n",
        "    \n",
        "    notes=[]\n",
        "    notes_to_parse = None\n",
        "    \n",
        "    #parsing a midi file\n",
        "    midi = converter.parse(file)\n",
        "\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "    for part in s2.parts:\n",
        "    \n",
        "        if 'Piano' in str(part): \n",
        "        \n",
        "            notes_to_parse = part.recurse() \n",
        "            for element in notes_to_parse:\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                \n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return np.array(notes)"
      ],
      "metadata": {
        "id": "-rrVpefAhocc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from music21 import converter, instrument, note, chord\n",
        "import numpy as np\n",
        "\n",
        "path='/path'\n",
        "files=[i for i in os.listdir(path) if i.endswith(\".midi\")]\n",
        "\n",
        "notes_array = np.array([read_midi(path+i) for i in files])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0J1ZFu4iIg9",
        "outputId": "67ad601a-72bb-4843-a57a-57088cd28df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notes_ = [element for note_ in notes_array for element in note_]\n",
        "\n",
        "unique_notes = list(set(notes_))"
      ],
      "metadata": {
        "id": "UNV_ZESkiuW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_music=[]\n",
        "\n",
        "for notes in notes_array:\n",
        "    temp=[]\n",
        "    for note_ in notes:\n",
        "            temp.append(note_)            \n",
        "    new_music.append(temp)\n",
        "    \n",
        "new_music = np.array(new_music)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn_GaFdxjAtg",
        "outputId": "21fc74f3-53b4-424a-f0b4-097a8ed05d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_timesteps = 32\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for note_ in new_music:\n",
        "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
        "        \n",
        "        input_ = note_[i:i + no_of_timesteps]\n",
        "        output = note_[i + no_of_timesteps]\n",
        "        \n",
        "        x.append(input_)\n",
        "        y.append(output)\n",
        "        \n",
        "x=np.array(x)\n",
        "y=np.array(y)"
      ],
      "metadata": {
        "id": "_whVArs4jMHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_x = list(set(x.ravel()))\n",
        "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
      ],
      "metadata": {
        "id": "mKqSOogvjNw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_seq=[]\n",
        "for i in x:\n",
        "    temp=[]\n",
        "    for j in i:\n",
        "        temp.append(x_note_to_int[j])\n",
        "    x_seq.append(temp)\n",
        "    \n",
        "x_seq = np.array(x_seq)"
      ],
      "metadata": {
        "id": "cEyev7nfjXHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_y = list(set(y))\n",
        "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
        "y_seq=np.array([y_note_to_int[i] for i in y])"
      ],
      "metadata": {
        "id": "y5bhg4l4jehR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "4_u1rMh8jiMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_vocab=len(x_seq)"
      ],
      "metadata": {
        "id": "sDA-LxMYkWu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "import keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
        "\n",
        "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "    \n",
        "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "\n",
        "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "           \n",
        "model.add(GlobalMaxPool1D())\n",
        "    \n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(len(unique_y), activation='softmax'))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)   \n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtBVAif0jr8U",
        "outputId": "656fa769-aecd-4be2-e983-e90e7724e0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 32, 100)           2900      \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 32, 64)            19264     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 8, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 8, 256)            98560     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 28)                7196      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 218,416\n",
            "Trainable params: 218,416\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=0)"
      ],
      "metadata": {
        "id": "QV5K-tHlkpwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW24U42Lj0vE",
        "outputId": "08cfabc2-84a3-4108-a9bb-00322fbce084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 2.3072 - val_loss: 2.3358\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 2.3077 - val_loss: 2.3411\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 2.3084 - val_loss: 2.3406\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 2.3074 - val_loss: 2.3390\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 2.3061 - val_loss: 2.3346\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3091 - val_loss: 2.3349\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3081 - val_loss: 2.3400\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 2.3086 - val_loss: 2.3406\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 2.3076 - val_loss: 2.3348\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3056 - val_loss: 2.3362\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 2.3061 - val_loss: 2.3336\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3079 - val_loss: 2.3390\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3066 - val_loss: 2.3450\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 2.3089 - val_loss: 2.3399\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3055 - val_loss: 2.3351\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 2.3065 - val_loss: 2.3383\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 2.3109 - val_loss: 2.3366\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3070 - val_loss: 2.3373\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 2.3049 - val_loss: 2.3377\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3054 - val_loss: 2.3347\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3055 - val_loss: 2.3358\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3056 - val_loss: 2.3359\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3101 - val_loss: 2.3389\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 2.3079 - val_loss: 2.3375\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 2.3085 - val_loss: 2.3364\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3084 - val_loss: 2.3413\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3077 - val_loss: 2.3401\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3088 - val_loss: 2.3372\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3076 - val_loss: 2.3376\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 17ms/step - loss: 2.3080 - val_loss: 2.3334\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3093 - val_loss: 2.3366\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3120 - val_loss: 2.3354\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3139 - val_loss: 2.3376\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 2.3085 - val_loss: 2.3371\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 2.3104 - val_loss: 2.3365\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3078 - val_loss: 2.3370\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3100 - val_loss: 2.3369\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3101 - val_loss: 2.3373\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 2.3087 - val_loss: 2.3380\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3109 - val_loss: 2.3349\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3100 - val_loss: 2.3369\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3079 - val_loss: 2.3401\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 2.3086 - val_loss: 2.3370\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3095 - val_loss: 2.3344\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3086 - val_loss: 2.3446\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3105 - val_loss: 2.3417\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 2.3085 - val_loss: 2.3377\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3077 - val_loss: 2.3345\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3076 - val_loss: 2.3377\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 2.3088 - val_loss: 2.3410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('best_model.h5')"
      ],
      "metadata": {
        "id": "b1eYeeURlIri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "ind = np.random.randint(0,len(x_val)-1)\n",
        "\n",
        "random_music = x_val[ind]\n",
        "\n",
        "predictions=[]\n",
        "for i in range(100):\n",
        "\n",
        "    random_music = random_music.reshape(1,no_of_timesteps)\n",
        "\n",
        "    prob  = model.predict(random_music)[0]\n",
        "    y_pred= np.argmax(prob,axis=0)\n",
        "    predictions.append(y_pred)\n",
        "\n",
        "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
        "    random_music = random_music[1:]"
      ],
      "metadata": {
        "id": "7R9emyatlQKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
        "predicted_notes = [x_int_to_note[i] for i in predictions]"
      ],
      "metadata": {
        "id": "tw5Ij6aBlbf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_midi(prediction_output):\n",
        "   \n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    for pattern in prediction_output:\n",
        "        \n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                \n",
        "                cn=int(current_note)\n",
        "                new_note = note.Note(cn)\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "                \n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "            \n",
        "        else:\n",
        "            \n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        offset += 0.5\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='f2.midi')\n"
      ],
      "metadata": {
        "id": "pVvBWI0qlgZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from music21 import *\n",
        "convert_to_midi(predicted_notes)"
      ],
      "metadata": {
        "id": "gzZgqAFblm6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code was inspired by the work of:\n",
        "https://towardsdatascience.com/music-in-python-2f054deb41f4\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2020/01/how-to-perform-automatic-music-generation/\n",
        "\n",
        "https://python-course.eu/applications-python/musical-scores-with-python.php\n",
        "\n",
        "https://stackoverflow.com/questions/44793221/python-fractal-box-count-fractal-dimension\n"
      ],
      "metadata": {
        "id": "TOOOmupi1JI-"
      }
    }
  ]
}